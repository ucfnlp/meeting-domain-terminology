O_K. So we're gonna try to finish by five so people who want to can go hear Nancy Chang's talk,
And you guys are g- giving talks on tomorrow and Wednesday lunch times, right? That's great.
O_K so, do y- do you know what we're gonna do?
two things uh we'll introduce ourselves and what we do.
And um we already talked with Andreas,
some lines of code were already written today
em we have talked this morning with the - with Tilman about the generator.
w- we have - we face
grammar for the English generation which is sort of starting from scratch and
um style that is implemented in the German system
are then able not only to produce
strings but also the syntactic parse
the syntactic tree that is underneath in the syntactic structure
That sounds good. Johno, are you gonna have some time t- to do that uh w- with these guys?
I may not have time to
continue either all through tonight or tomorrow on whatever
to get the er parser interface working.
Also of course it would be  really  nice to know what the  plans  are, in addition to what's sort of already in  code.
Um we're here through Sunday, so
and how we can change them.
Right. This is then out of deference to our
Uh he will be in Washington, though.
facing to - to what we've sort of been doing here
part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human.
we have first looked at a simple sentence that
And maybe some model will tell us, some G_P_S module, in the mobile scenario where the person is at the moment.
first of all what are - I should've
And our system led people
here, to a point where they were facing a wall
to a completely different point where they can look at it and take a picture.
and so forth. There are all kinds of decisions that we have identified
And we also want to look closely on the linguistic information that
suitable interfaces and a belief-net for
a module that actually tries to guess what
enrich or augment the M_-three-L_ structures with what it thought
these bits of additional information are going to be
embedded into the M_-three-L_ structure
extra information. We don't really -
right now I know the G_I_S from email
that distinction, maybe somebody will go ahead and implement it.
Well the obvious one would be if - if you envision this as a module within SmartKom, where exactly would that
I mean basically this is what attention-recognition literally sort of
were originally trying to do
doesn't seem to quite fit into SmartKom currently
right now is only selecting among
enriched by the domain knowledge and
the um discourse modeler and so on.
And then it would be available to action planning and - and others.
Pa- pass over any  you know, questions or concerns that you have.
uh the - the two levels will be
uh standing here for the generation module and the other is - is
my understanding of what SmartKom uh is supposed to be
Let me s-  expand on that a  little  bit from the point of view of the generation.
There's a  first   cut  at a belief-net that - that doesn't - it - isn't fully uh instantiated, and in particular some of the - the combination rules and ways of getting the - the conditional probabilities aren't there.
So  one  of the decisions is what we call this A_V_E thing.
So that's a- a discrete decision. There are only three possibilities and the uh - what one would like is for this uh, knowledge modeling module to
which of those it  is  and give it to the planner.
uh th- the current design suggests that
give it to the dialogue planner and say this, you know
That would get expressed and then hopefully
uh, We probably  won't  do this early on,
While we're on the subject I just wanted to give you a sort of head's up
some months from now we said "O_K we're now ready to
in terms of querying about some of these decisions.
my suggestion then is that you um
look into the currently ongoing discussion about how the
of how dialogues would proceed.
The - these um transition networks
Well uh Marcus  Lerkult  is actually implementing that
um we should early on make sure that they
have the flexibility that we need.
the - the dialogue behavior or the action -
of planning, and action, and a route planner and
encapsulated from th- the dialogue system.
data as in a query and then you get
So I think the idea of having a, you know, transition diagram for the grammar of conversations is a good idea.
it's not just an  information  retrieval system.
what's called the action plan and what's really the dialogue manager.
is based on slots that have to be filled and the um
very complex structured information in these slots and
um being taken into consideration.
completely settled there so this is really an ongoing discussion and that's
because um again in- in Deep Map we have faced and implemented those problems once already maybe we can even shuffle some know how from there to
And um you are probably also involved in that, right?
Those are the - I think the - the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it -
I didn't think of the internal working of the uh
the action planner and the language - uh the function model as sort of relevant.
But um the internal workings of
of the - whether you know there're dialogue -
action planners that work with belief-nets that are action planners that work with you know state  automata .
is going to  take  some  spec  and s-
is going to be very much caught up with what
If the  parser  and the
been defined yet but there's gonna be some kind of feedback and input from
into all the analysis modules,
telling them what to expect and what the current state of the discourse is.
Beyond what's currently being implemented which is just word lists.
Of - of special interest.
And even on - on a more basic level the - the action planner
an expressive power that can deal with these structures.
And not just um say
um - um the dialogue um will consist of ten possible states
Would there be any chance
of getting the  terminology   changed so that the dialogue planner was called a "dialogue planner"?
a  route  planner or - It's  really  gonna be an action planner.
So if there is resistance
does the planning of the uh
think it's really - really wrong headed for
Yeah I think just the - the spatial planner and the route planner
a printout of the communication between those two fills up
but um so this is um definitely a good point to get uh
gonna be responsible for the implementation of this action planner.
the action planner should not be - or the dialogue manager in that case should not um w- have to worry about whether it's interfacing with um something that does route planning in this way or that way huh, it j-
will fill in some parameters about what the person wants. One could  well  imagine
uh,  route  planning, let's say, will  also  have questions that it would  like  to ask the user.
uh. the  dialogue  manager and to the  output  module and back  around.
an architecture where there really is a pers- a def- well-defined interface.
I totally agree. But - but what it nee- but th- what the point is the- in that case the  dialogue  manager is sort of  event  driven.
So the  dialogue  manager may think it's in a  dialogue   state
of  one  sort, and this -
one of these  planning  modules comes along and says "hey,  right  now we need
So that  forces  the dialogue manager to change state.
kernel modules with kernel functionality that you can plug uh
certain applications like tourist information or
um the home scenario with uh controlling a V_C_R and so on.
And then extend it to
evade but, at- at least it makes sense to me that sooner or later uh -
the function modeler and a self-description of the
um external service haggle it out and
to interface with planner-A_, planner-B_, planner-C_ and so forth.
But we are facing of course much more
Then of course, the uh
and um so we - we're thinking, for example
how much syntactic analysis actually happens already in the parser.
and whether one could interface to that
Yeah, are there currently is uh no syntactic analysis
S- so uh y- we - we looked at the e- current pattern matching thing.
Uh, So what are - what are the  plans  roughly?
it's to - to integrate and syntactic analysis.
add some more features like segmentation.
uh - partic- d- I mean have you thought through - ?
But the people at D_F_-
People at D_F_K_I have  written  a fair number of  parsers.
Other - you know,  people  over the  years.
uh have  written  various parsers at D_F_K_I. None of them
Yeah, uh the problem is
And they are not fast enough.
cuz of um speech recognition errors and
So, um - So there was a  chunk  parser
Oh from - from Stuttgart, yeah, also
the chunk parser itself was pretty  stupid  and then there was a
was a learning-based approach which
From Michael Strube, I've heard very good stuff about the chunk parser that is done by FORWISS,
So this is sort of - came as a surprise to  me  that
whether there is some synergy
constraints,  that you want it to be  small  and  fast  and  so   forth,
Purely   finite-state transducers are not so good for German since there's um
The  word   order is - is uh not fixed
um choice between uh this processing and that processing and my template matcher.
and uh at least for German you have all - all of the - uh
What - what's happening on-line is
So in German then you actually do case matching and things like in the - in the pattern matcher or not?
um Not yet but it's planned to do that.
if you're trying to build some fast parser
more adequate for English and in German um
the form of - of
uh -  conceptual  grammar that - that w- we
So we  talked  about the  fact  that
that will be then fed to the  function  module,
So there are these decisions. And then
one   half  of this we talked about at  little  bit is
how  if  you  had  the right  information,  if you knew something about what was  said  and about th- the something about
That information, and also about the
into  decision  networks and give you  decisions.
But the  other   half  of the problem is
So what you  might  try to do is just build more  templates,  saying uh we're trying to build a templ- you know build a template that w- uh  somehow  would capture the fact that
uh from  our  point of view this is also a research project
is a  very   deep  semantics based on  cognitive   linguistics  and the notion that there are a  relatively   small  number
of  primitive  conceptual  schemas  that  characterize  a lot of  activity.
are characterized in terms of  containers.  Going in and out
But also, importantly for Lakoff and these guys is all sorts of  metaphorical
So, what we're  really  trying to do
is to map from the  discourse
to the  conceptual  semantics level.
So  another  one of these primitive,
what are called " image  schemas",
And that all  sorts  of things,  particularly  in the tourist domain, can be represented in  terms  of uh source, path and goal. So the idea would be could we build an  analyzer  that would take an  utterance
The goal is this, the pers- the, uh traveler is that, uh the sor- w- where we are at now is is this, they've mentioned possible obstacles, et cetera."
The  processing  of that,  both  on the  input  end,
recognizing  that  certain   words  in a language  talk   about   containers  or  goals,  et  cetera,
is going to be  not  about using this in applications, but about modeling how children might  learn
And how do you envision
if and then there would be another module that takes that
deep semantic construction and map it onto the current context to find out what the person
So  part  of what you'll get out of this will be the fact tha- w- if it works right, O_K, that this is an agent that wants to go to this place and that's their goal  and  there will be additional  situational  information.
Uh, O_K, part of it comes from the  ontology.  The tower is  this  kind of object. Part of it comes from the  user  model.
And the idea of the  belief-net  is it combines
information  from the  dialogue  which comes across in this  general  way,
along with  specific  information from the  ontology  about the kinds of objects involved and about the  situation
about "Is it raining?" I don't know. Whatever it is. And so that's the belief-net that we've laid  out.
And so th- the  coupling  to the situation comes in this model from, at th- at th- at the belief-net, combining evidence from the dialogue with the ontology with the situation.
